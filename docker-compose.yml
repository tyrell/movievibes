services:
  # Movie Vibes Application (Backend + Frontend)
  movievibes:
    build: .
    container_name: movievibes-app
    ports:
      - "8080:8080"
    environment:
      # Spring profiles
      - SPRING_PROFILES_ACTIVE=docker
      # Ollama connection
      - SPRING_AI_OLLAMA_BASE_URL=http://ollama:11434
      - SPRING_AI_OLLAMA_MODEL=llama3:latest
      - SPRING_AI_OLLAMA_CHAT_MODEL=llama3:latest
      # OMDb API configuration
      - OMDB_URL=https://www.omdbapi.com/
      - OMDB_API_KEY=${OMDB_API_KEY}
    depends_on:
      ollama:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Ollama for local AI model (with pre-downloaded models)
  ollama:
    build:
      context: .
      dockerfile: Dockerfile.ollama
    container_name: movievibes-ollama
    command: ["serve"]
    ports:
      - "11434:11434"
    restart: unless-stopped
    environment:
      - OLLAMA_HOST=0.0.0.0
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s


